{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676692e6",
   "metadata": {},
   "source": [
    "### Postprocessing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "import os, uuid\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connection string for the Storage Account as an environment variable\n",
    "os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"] = \"DefaultEndpointsProtocol=https;AccountName=sluganalyses;AccountKey=DiKILCHG3lKTjOFQWtVj52YYygQkfRTv15YjG3KR1zF8pOxJxmRjNtCjgHEYwsj9v+YNPFDpgIU8YFf/+/PF4w==;EndpointSuffix=core.windows.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd753015",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'bucket1'\n",
    "CONTAINER_NAME = BUCKET\n",
    "CONNECT_STR = os.getenv('AZURE_STORAGE_CONNECTION_STRING') # Get connection string from env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BlobServiceClient object which will be used to read container client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECT_STR)\n",
    "container_client = blob_service_client.get_container_client(container=CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the blobs in the container\n",
    "blob_list = container_client.list_blobs()\n",
    "file_dates, files_list = ([], [])\n",
    "for blob in blob_list:\n",
    "    files_list.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with filenames and file date as a separate column\n",
    "files_df = pd.DataFrame(files_list, columns = ['file'])\n",
    "plot_files = files_df['file']\n",
    "plot_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0800c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_client = ContainerClient.from_connection_string(conn_str=CONNECT_STR, container_name=CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of load cases that are covered by the timetrace files\n",
    "lc_files = []\n",
    "for file_p in plot_files:\n",
    "    lc_files.append(file_p[:len(file_p) - 8])\n",
    "    \n",
    "lc_files = list(dict.fromkeys(lc_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9aa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists of take processed results\n",
    "load_cases = []\n",
    "out_verDisp_mm_n5 = []\n",
    "out_oopDisp_mm_n5 = []\n",
    "out_oopDisp_mm_n2 = []\n",
    "out_endBend_kNm_n6 = []\n",
    "out_supReac_kN_n3 = []\n",
    "out_supReac_kN_n4 = []\n",
    "\n",
    "# Loop through and process each load case and each plot file in each load case\n",
    "for lc in lc_files:\n",
    "    load_cases.append(lc)\n",
    "    for tt in ['T1', 'T3', 'T4', 'T5', 'T6', 'T7']:\n",
    "        # Form the filename from the load case reference\n",
    "        file_p = f'{lc}.{tt}.mplt'\n",
    "        \n",
    "        # Download blob as StorageStreamDownloader object (stored in memory)\n",
    "        downloaded_blob = container_client.download_blob(file_p)\n",
    "        plot_raw = pd.read_csv(StringIO(downloaded_blob.content_as_text()), skiprows=12, delimiter='\"')\n",
    "        dat_dt = {'time':plot_raw.iloc[:,3].dropna(), 'value':plot_raw.iloc[:,5].dropna()}\n",
    "        dat_df = pd.DataFrame(dat_dt)\n",
    "\n",
    "        # Breakdown of types of timetrace\n",
    "        motions = ['T1', 'T2', 'T3', 'T4']\n",
    "        moments = ['T5', 'T6']\n",
    "        reactin = ['T7']\n",
    "\n",
    "        # Some unit conversions depending on type\n",
    "        # Use mm for displacement ranges\n",
    "        if (any(x in file_p for x in motions)):\n",
    "            dat_df.value = dat_df.value*1000\n",
    "\n",
    "        elif (any(x in file_p for x in moments)):\n",
    "            dat_df.value = dat_df.value/1000\n",
    "\n",
    "        elif (any(x in file_p for x in reactin)):\n",
    "            dat_df.value = dat_df.value/1000\n",
    "\n",
    "        # Calculate the range\n",
    "        dat_range = dat_df.value.max() - dat_df.value.min()\n",
    "        print(file_p[:len(file_p) - 8])\n",
    "        print(f'Max: {round(dat_df.value.max(), 1)}, Min: {round(dat_df.value.min(), 1)}') \n",
    "        print('Range: ', round(dat_range, 1), '\\n')\n",
    "\n",
    "        # Collect the results\n",
    "        if 'T1' in file_p:\n",
    "            out_verDisp_mm_n5.append(round(dat_range, 2))\n",
    "        elif 'T3' in file_p:\n",
    "            out_oopDisp_mm_n5.append(round(dat_range, 2))\n",
    "        elif 'T4' in file_p:\n",
    "            out_oopDisp_mm_n2.append(round(dat_range, 2))\n",
    "        elif 'T5' in file_p:\n",
    "            out_endBend_kNm_n6.append(round(dat_range, 2))\n",
    "        elif 'T6' in file_p:\n",
    "            out_supReac_kN_n3.append(round(dat_range, 2)) \n",
    "        elif 'T7' in file_p:\n",
    "            out_supReac_kN_n4.append(round(dat_range, 2))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7333132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compile the results in a single dataframe\n",
    "res_df = pd.DataFrame(load_cases, columns = ['load_case'])\n",
    "res_df['out_oopDisp_mm_n2'] = out_oopDisp_mm_n2\n",
    "res_df['out_supReac_kN_n3'] = out_supReac_kN_n3\n",
    "res_df['out_supReac_kN_n4'] = out_supReac_kN_n4\n",
    "res_df['out_verDisp_mm_n5'] = out_verDisp_mm_n5\n",
    "res_df['out_oopDisp_mm_n5'] = out_oopDisp_mm_n5\n",
    "res_df['out_endBend_kNm_n6'] = out_endBend_kNm_n6\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results as a csv\n",
    "res_df.to_csv(f'{BUCKET}_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
